Store the kafka  file in c drive only. if we try to store in the other file it  will give the error that file path is too long when we try to strt zookeper server.
C:\kafka\kafka\bin\windows>zookeeper-server-start.bat ..\..\config\zookeeper.properties------> to start zookeeper server
C:\kafka\kafka\bin\windows>kafka-server-start.bat ..\..\config\server.properties---->Start Kafka Server / Broker
************************************************************************************************************************
C:\kafka\kafka\bin\windows>kafka-server-stop.bat-->to stop kafka server.. use this command on the other termain other than the terminal
in which kafka server is running
To create topic
C:\kafka\kafka\bin\windows>kafka-topics.bat --create --topic java --bootstrap-server localhost:9092 --replication-factor 1 --partitio
ns 3
Created topic java.
*************************************************************************************************************************************************************************
Describe topics
C:\kafka\kafka\bin\windows>kafka-topics.bat --bootstrap-server localhost:9092 --describe --topic java
Topic: java     TopicId: gI2J47QdT2qEksslN9kxvQ PartitionCount: 3       ReplicationFactor: 1    Configs:
        Topic: java     Partition: 0    Leader: 0       Replicas: 0     Isr: 0
        Topic: java     Partition: 1    Leader: 0       Replicas: 0     Isr: 0
        Topic: java     Partition: 2    Leader: 0       Replicas: 0     Isr: 0
***********************************************************************************************************************************************************************
C:\kafka\kafka\bin\windows>kafka-console-producer.bat --broker-list localhost:9092 --topic java-->to start the producer
**********************************************************************************************************
kafka-console-consumer.bat --bootstrap-server localhost:9092 --topic java --from-beginning-->to start the consumer
**************************************************************************************************************************
C:\kafka\kafka\bin\windows>kafka-consumer-groups.bat --bootstrap-server localhost:9092 --list-->to see how many consumer group 
are present
*************************************************************************************************************************
C:\kafka\kafka\bin\windows>kafka-consumer-groups.bat --bootstrap-server localhost:9092 --describe --group javaConsmuer-group-3
it describe the particular consumer group "javaConsmuer-group-3"-->this is the consumer group
**************************************************************************************************************
C:\kafka\kafka\bin\windows>kafka-console-consumer.bat --bootstrap-server localhost:9092 --topic java --group myConsumerGroup
given the group name for the consumer

***************************************************************************************************************************


C:\kafka\kafka\bin\windows>kafka-topics.bat --create --topic java4 --bootstrap-server localhost:9092, localhost:9093, localhost:9094 --replication-factor 3 --partitions 3
It will create one topic with three copy . In my case there are three brocker. These brocker will have a copy of the data
******************************************************************************************************************
Multiple producer can happen for same topic
******************

Topics-->
A stream of message belonging to particular category is called a topic.
It is logical feed name to whch records are published.
It is Simlar to a table in a database.(records are considred message here)
Unique identifier of topic is it name.
we can create as many topics as we want.
we can create the topic for finance->this topics contain finance related messagge just like finance table
sport topic
******************************************************************************************************************
kafka cluster-->Kafka Broker-->kafka topics-->partition
*********************************************************************
Topics are split into partions. All the message within the partion are ordered and immutable. Each message within a partion 
has unique id known as offset
**********************
Replicas are backup of partion. replicas are never read or write data. they are used to prevent data loss.
********************************
producer are application that produces message to the topics within a cluster using the producing Apis. they produce message at topic level or partion level
****************************************************************************************************
Consumers are always associated with exactly one consumer group.
A consumer group is a group of related consumer that perform a task.
consumer are application tht read data from topics
*****************************************************************
Brokers are simple software processes who maintain and manage the published message.
Also known as kafka servers.
Brokers also manages the conumer-offsets and are responsible for the delivery of message to the right consumers.
A set of brokers who are communicating with each other to perform the management and maintanence task are collectively known as
kafka cluster.
we can add more broker in a alread runnning kafka cluster without any downtime
****************************
Zookeeper-->
it is used to moniotr kafka cluster and cordinate with each broker
keeps all the metadata informaion related to kafka cluster in the form of key value pair.
Metadata include -->Condfiguration information. Health status of each broker. 
********************************************************************************************************************
Kafka is 
Sclable->Horizontal Scaling is done by adding new brokers to the existing cluster.
Fault tolerence->Kafka cluster can handle failures because of its distributed nature.
Durable-->Kafka uses "Distributed commit log" which means message persist on a disk as fast as possible.
Zero down time-->It ensure zero downtime when required number of brokers are present in the cluster
**************************************************************
It is strongly recomended to run odd no of zookeper cluster
***************************************************************************
Leader will be decided by the partition. suppose there are three partion and two brocker then brocker 1 may be the leader partion 1 and 3 
and brocker 2 may be the leader of partion 2.
**************************************************************************************
The replicated group of server is called quoroum.zookeeper server run as leader folower node. If leader fails a new leader 
is elected.
************************************************************************************
Kafka cluster is managed by Zookeeper clutster(Zookeeper cluster have zookeeper node)
***********************************
Never no of replication factor should be greater than the no of avilable brocker.Brocker is nothing but a kafka server.
***********************************************************************
No of partition we always can increase but we never decrease the no of the partition.
*****************************************************************************************
we can move the partition from one brocker to another broker 
****************************************************
we can increase the replication factor
***********************************************************************************************************
we can change the topic partition
**********************************************************************************************************
we can increase the partition 
****************************************************************************************************
Group leader--> In Kafka, when several consumers come together to form a group (a consumer group) to read data, 
the first consumer that connects is automatically chosen as the group leader.
This leader keeps track of all the other consumers that are currently connected as part of the group
 Whenever a new consumer joins the group or an existing one leaves, the group leader organizes a rebalance. This means the leader reassesses and redistributes the tasks 
(which parts of the data each consumer should handle) among all current members.
*************************************************************************************************
Group cordinator-->In a Kafka system, which is used to handle and store real-time data streams, there are servers known as brokers. 
Some of these brokers are given a special role called "group coordinators."
When a consumer (a program that reads and processes data) starts, it first needs to find out who the manager (coordinator) is for its group. 
It does this by sending a "FindCoordinator" request. 
Once the consumer knows who the coordinator is, it tells the coordinator that 
it wants to join the group by sending a "Join Group" request.While the consumer is working, it regularly sends a "Heartbeat" request to the coordinator. 
This lets the coordinator know that the consumer is still active and working.
****************************************************************************************************
5. During the time the rebalancing process is happening,
 the consumers in that group can't read any messages. They need to wait until the rebalance is complete and they have 
their new instructions.
*************************************
offset-->In Kafka, each message or record in a partition is given a unique number called an "offset". 
This number helps identify each record uniquely within its partition. 
***********************************
Log-end Offset:
This is the offset of the newest record added to a partition.
The log-end offset tells you what the current last page (or record number) is.
************
Current Offset:
This offset points to the last record that Kafka has sent to a consumer the last time it asked for data.
***************************************
Committed Offset:
Simple Explanation: When you're consuming records (like reading pages in a book), 
marking an offset as committed is like telling the system, "I've read up to here."
************************************************
Internals when producer send a message-->
Message:-key:
payload:"abcd"
topic
partition:
offset:
timestamp:
************************************************************
consumer.poll method is used by Kafka consumers to fetch data from the broker. 
When you call this method, the consumer reaches out to the Kafka broker and requests any new records that are available since the last poll.
Request for Records: You specify a timeout when calling consumer.poll(timeout). The consumer waits for the specified duration to receive any new records from the server. The duration can be set based on how responsive you want your consumer to be.
Batch of Records: The method returns a list of records that can be processed by the consumer. These records are grouped by the partitions they came from, allowing efficient processing.
Handling Data: Once records are fetched, your application can process them accordingly.
**********************************
consumer.commit method is used to manually commit the offsets of records that have been processed.
 When you commit an offset, you are telling Kafka that the consumer has successfully processed all prior records up to that offset. 
The committed offset is used as a checkpoint from which the consumer can resume reading in case of a failure or restart.
***************************
Types of Commit:
Synchronous Commit: You can commit offsets synchronously using consumer.commitSync().
This method will block until the broker confirms the commit, ensuring reliability at the cost of latency and throughput.
Asynchronous Commit: You can also commit offsets asynchronously using consumer.commitAsync(). 
This method does not block; it sends the offsets to be committed and immediately returns to allow further processing.
*****************************************************




